p8105\_hw3\_hw2849
================
hw2849
2021.10.13

``` r
library(tidyverse)
library(timeDate)
library(p8105.datasets)
data("instacart")
data("brfss_smart2010")

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)
```

## Problem 1

``` r
instacart %>% 
  group_by(aisle_id) %>% 
  
  ## count for how many aisles and orders in each aisle
  summarize(order_counts = n()) %>% 
  
  ## ranking aisles by the number of orders
  mutate(
    ranking = min_rank(desc(order_counts))
    ) %>% 
  
  ## find the aisle of the most items ordered from
  filter(min_rank(ranking) < 2)
```

    ## # A tibble: 1 × 3
    ##   aisle_id order_counts ranking
    ##      <int>        <int>   <int>
    ## 1       83       150609       1

``` r
## Sort aisles with 10000 more orders
plot_df = instacart %>% 
  count(aisle, name = "orders_over_10000") %>% ## count for variable
  filter(orders_over_10000 > 10000) %>% 
  mutate(
    aisle = factor(aisle),
    aisle = fct_reorder(aisle, orders_over_10000)
  ) %>% 
  ggplot(aes(x = aisle, y = orders_over_10000)) + 
  geom_point() + 
  labs(
    title = "Figure 1: Aisles of over 10000 items ordered",
    x = "Aisle",
    y = "Number of items ordered"
  ) + 
  theme(axis.text.x = element_text(angle = 90))

plot_df
```

<img src="p8105_hw3_hw2849_files/figure-gfm/unnamed-chunk-2-1.png" width="90%" />

``` r
## A table for three most popular items in “baking ingredients”, “dog food care”, and “packaged vegetables fruits”
table = instacart %>% 
  group_by(aisle) %>% 
  filter(
    aisle %in% c("baking ingredients", 
                 "dog food care", 
                 "packaged vegetables fruits")
    ) %>% 
  count(product_name, name = "counts") %>% 
  mutate(
    ranking = min_rank(desc(counts))
  ) %>% 
  filter(ranking < 4)

table
```

    ## # A tibble: 9 × 4
    ## # Groups:   aisle [3]
    ##   aisle                      product_name                         counts ranking
    ##   <chr>                      <chr>                                 <int>   <int>
    ## 1 baking ingredients         Cane Sugar                              336       3
    ## 2 baking ingredients         Light Brown Sugar                       499       1
    ## 3 baking ingredients         Pure Baking Soda                        387       2
    ## 4 dog food care              Organix Chicken & Brown Rice Recipe      28       2
    ## 5 dog food care              Small Dog Biscuits                       26       3
    ## 6 dog food care              Snack Sticks Chicken & Rice Recipe …     30       1
    ## 7 packaged vegetables fruits Organic Baby Spinach                   9784       1
    ## 8 packaged vegetables fruits Organic Blueberries                    4966       3
    ## 9 packaged vegetables fruits Organic Raspberries                    5546       2

``` r
## A table for mean hour of the day Pink Lady Apples and Coffee Ice Cream
table_mean_hour = instacart %>% 
  group_by(product_name, order_dow) %>% 
  filter(
    product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")
      ) %>% 
  summarize(
    mean_hour = mean(order_hour_of_day)
    ) %>% 
 mutate(
   order_dow = lubridate::wday(order_dow + 1, label = TRUE)
   ) %>% 
  pivot_wider(
  names_from = order_dow,
  values_from = mean_hour
  )
```

    ## `summarise()` has grouped output by 'product_name'. You can override using the `.groups` argument.

``` r
table_mean_hour
```

    ## # A tibble: 2 × 8
    ## # Groups:   product_name [2]
    ##   product_name       Sun   Mon   Tue   Wed   Thu   Fri   Sat
    ##   <chr>            <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>
    ## 1 Coffee Ice Cream  13.8  14.3  15.4  15.3  15.2  12.3  13.8
    ## 2 Pink Lady Apples  13.4  11.4  11.7  14.2  11.6  12.8  11.9

First, we have 1384617 observations with 15 variables in `instacart`
dataset, which including user ids, product names, product aisles, aisles
numbers, the day of the week and the hour of the day on which the order
was placed.

There are 134 aisles, and the most items ordered from aisle 83, which is
fresh vegetables. The plot shows the number of items ordered in aisles
that are more than 10000 items ordered.

The table shows three most popular items in aisles “baking ingredients”,
“dog food care”, and “packaged vegetables fruits”. For example,top three
popular items of “baking ingredients” are light brown sugar, pure baking
soda, and cane sugar.

The last table summarizes the mean hour of the day that “Pink Lady
Apples” and “Coffee Ice Cream” are ordered on each day of the week. For
instance, the mean hour at “Coffee Ice Cream” are ordered on day “3” is
15.31818.

## Problem 2

``` r
## Data cleaning on `Overall Health` topic
health_data_df = brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  rename(state = locationabbr, county = locationdesc) %>% 
  group_by(topic) %>% 
  filter(topic == "Overall Health") %>% 
  mutate(
    response = factor(response, 
                      levels = c("Poor", "Fair", "Good", "Very good", "Excellent"))
    ) %>% 
  arrange(response, .by_group = TRUE) 
```

-   In 2002, which states were observed at 7 or more locations? What
    about in 2010?

``` r
## 7 or more locations of a state observed in 2002
observation_2002 = health_data_df %>% 
  filter(year == "2002") %>% 
  count(state, name = "state_counts") %>% 
  filter(state_counts >= 7)

## 7 or more locations of a state observed in 2010
observation_2010 = health_data_df %>% 
  filter(year == "2010") %>% 
  count(state, name = "state_counts") %>% 
  filter(state_counts >= 7)
```

-   A data set limits to `Excellent` responses, and contains year,
    state, and mean of `data_value` across locations within a state. A
    lined-plot of the mean value over time within a state.

``` r
mean_data_value = health_data_df %>% 
  group_by(year, state) %>% 
  filter(response == "Excellent") %>% 
  summarize(mean_value = mean(data_value)) ##  pivot_wider(names_from = year, values_from = mean_value) 
```

    ## `summarise()` has grouped output by 'year'. You can override using the `.groups` argument.

``` r
## A spaghetti plot that shows lines for the mean value of each state across years
spaghetti_plot = ggplot(mean_data_value) + 
  geom_line(aes(x = year, y = mean_value, color = state)) + 
  labs(
    title = "Figure 2: Average value across locations within each state over years",
    x = "State",
    y = "Average value"
  )

spaghetti_plot
```

    ## Warning: Removed 3 row(s) containing missing values (geom_path).

<img src="p8105_hw3_hw2849_files/figure-gfm/unnamed-chunk-5-1.png" width="90%" />

-   Make a two-panel plot showing, for the years 2006, and 2010,
    distribution of data\_value for responses (“Poor” to “Excellent”)
    among locations in NY State.

``` r
NY_response_df = health_data_df %>%
  filter(
    state == "NY", 
    year %in% c(2006,2010)
    ) %>% 
  ggplot(aes(x = response, y = data_value)) + 
  geom_boxplot() + 
  facet_grid(.~year) + 
  labs(
    title = "Figure 3: Data value across responses in NY State", 
    x = "Response levels",
    y = "Data Value"
  ) 

NY_response_df
```

<img src="p8105_hw3_hw2849_files/figure-gfm/unnamed-chunk-6-1.png" width="90%" />

In this problem, we focused on the topic of ‘Overall Health’. Firstly,
changed the variable names, for example, ‘locationabbr’ was changed into
‘state. Then, values of variable ’response’ was reordered in levels of
{Poor, Fair, Good, Very good, Excellent}.

Looking at the data frame, in 2002, there were 36 states were observed
at 7 or more locations. However, in 2010, there were 45 states were
observed.

Next, we constructed a dataset that limits to ‘Excellent’ responses, and
grouped by ‘year’, ‘state’, and created a variable ‘mean\_value’ that
indicates the average values of ‘data\_value’ across locations within a
state. Graphed a spaghetti plot that shows lines for the mean value of
each state across years.

Lastly, generated a two-panel plot showing the distribution of
‘data\_value’ for response in 2006 and 2010 for NY state.

## Problem 3

``` r
accelerometer_data = read_csv("./data/accel_data.csv") %>% 
  janitor::clean_names() %>% ## clean variable names
  pivot_longer( ## make the table readable
    activity_1:activity_1440,
    names_to = "activity_time",
    names_prefix = "activity_",
    values_to = "value"
  ) %>% 
  mutate( ## refactor the variables
    day = factor(day, levels = c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday")), 
    week = factor(week), 
    weekday_or_weekend = ifelse(day == "Sunday" | day == "Saturday", print("Weekend"), print("Weekday")), ## a new variable whether weekend/weekday
    activity_time = as.numeric(activity_time)
    ) %>% 
  arrange(week, day) ## reorder the variables by `day`
```

    ## Rows: 35 Columns: 1443

    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr    (1): day
    ## dbl (1442): week, day_id, activity.1, activity.2, activity.3, activity.4, ac...

    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

    ## [1] "Weekend"
    ## [1] "Weekday"

``` r
accelerometer_data %>% 
  group_by(day_id) %>% 
  summarize(total_time = sum(value)) %>% 
ggplot(aes(x = day_id, y = total_time)) + 
  geom_point() + 
  geom_line()
```

<img src="p8105_hw3_hw2849_files/figure-gfm/unnamed-chunk-8-1.png" width="90%" />

``` r
accelerometer_data %>% 
  ggplot(aes(x = activity_time, 
             y = value, 
             group = day_id, 
             color = day)
         ) +  
  geom_smooth(aes(group = day)) + 
  scale_x_continuous(
    breaks = c(0, 360, 720, 1080, 1440),
    labels = c("0AM", "6AM", "12PM", "6PM", "12AM")
  )
```

    ## `geom_smooth()` using method = 'gam' and formula 'y ~ s(x, bs = "cs")'

<img src="p8105_hw3_hw2849_files/figure-gfm/unnamed-chunk-9-1.png" width="90%" />

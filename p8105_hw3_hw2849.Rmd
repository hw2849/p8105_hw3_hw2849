---
title: "p8105_hw3_hw2849"
author: hw2849
date: 2021.10.13
output: github_document
---

```{r, message = FALSE, warning = FALSE}
library(tidyverse)
library(p8105.datasets)
data("instacart")
data("brfss_smart2010")

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)
```

## Problem 1
```{r}
instacart %>% 
  group_by(aisle_id) %>% 
  
  ## count for how many aisles and orders in each aisle
  summarize(order_counts = n()) %>% 
  
  ## ranking aisles by the number of orders
  mutate(
    ranking = min_rank(desc(order_counts))
    ) %>% 
  
  ## find the aisle of the most items ordered from
  filter(min_rank(ranking) < 2)


## Sort aisles with 10000 more orders
plot_df = instacart %>% 
  group_by(aisle_id) %>% 
  count(aisle_id, name = "orders_over_10000") %>% 
  filter(orders_over_10000 > 10000) 

  ggplot(plot_df, aes(x = aisle_id, y = orders_over_10000)) + 
    geom_point()
  

## A table for three most popular items in “baking ingredients”, “dog food care”, and “packaged vegetables fruits”
table = instacart %>% 
  group_by(aisle) %>% 
  filter(
    aisle %in% c("baking ingredients", 
                 "dog food care", 
                 "packaged vegetables fruits")
    ) %>% 
  count(product_name, name = "counts") %>% 
  mutate(
    ranking = min_rank(desc(counts))
  ) %>% 
  filter(ranking < 4)

table

## A table for mean hour of the day Pink Lady Apples and Coffee Ice Cream
table_mean_hour = instacart %>% 
  group_by(product_name, order_dow) %>% 
  filter(
    product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")
      ) %>% 
  summarize(
    mean_hour = mean(order_hour_of_day)
    ) %>% 
  
 ##??  lubridate::wday(order_dow + 1)   
## mutate(order_dow = wday(order_dow + 1))
 
pivot_wider(
  names_from = order_dow,
  values_from = mean_hour
)

table_mean_hour

```

First, we have 1384617 observations with 15 variables in `instacart` dataset, which  including user ids, product names, product aisles, aisles numbers, the day of the week and the hour of the day on which the order was placed. 

There are 134 aisles, and the most items ordered from aisle 83, which is fresh vegetables. The plot shows the number of items ordered in aisles that are more than 10000 items ordered. 

The table shows three most popular items in aisles “baking ingredients”, “dog food care”, and “packaged vegetables fruits”. For example,top three popular items of "baking ingredients" are light brown sugar, pure baking soda, and cane sugar. 

The last table summarizes the mean hour of the day that "Pink Lady Apples" and "Coffee Ice Cream" are ordered on each day of the week. For instance, the mean hour at "Coffee Ice Cream" are ordered on day "3" is 15.31818. 

## Problem 2
```{r}
## Data cleaning on `Overall Health` topic
health_data_df = brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  rename(state = locationabbr, county = locationdesc) %>% 
  group_by(topic) %>% 
  filter(topic == "Overall Health") %>% 
  mutate(
    response = factor(response, 
                      levels = c("Poor", "Fair", "Good", "Very good", "Excellent"))
    ) %>% 
  arrange(response, .by_group = TRUE) 

```

* In 2002, which states were observed at 7 or more locations? What about in 2010?
```{r}
## 7 or more locations of a state observed in 2002
observation_2002 = health_data_df %>% 
  filter(year == "2002") %>% 
  count(state, name = "state_counts") %>% 
  filter(state_counts >= 7)

## 7 or more locations of a state observed in 2010
observation_2010 = health_data_df %>% 
  filter(year == "2010") %>% 
  count(state, name = "state_counts") %>% 
  filter(state_counts >= 7)

```

* A data set limits to `Excellent` responses, and contains year, state, and mean of `data_value` across locations within a state. A lined-plot of the mean value over time within a state.

```{r}
mean_data_value = health_data_df %>% 
  group_by(year, state) %>% 
  filter(response == "Excellent") %>% 
  summarize(mean_value = mean(data_value)) ##  pivot_wider(names_from = year, values_from = mean_value) 
  
## A spaghetti plot that shows lines for the mean value of each state across years
spaghetti_plot = ggplot(mean_data_value) + 
  geom_line(aes(x = year, y = mean_value, color = state)) 

spaghetti_plot
```

* Make a two-panel plot showing, for the years 2006, and 2010, distribution of data_value for responses (“Poor” to “Excellent”) among locations in NY State.
```{r}
NY_response_df = health_data_df %>%
  filter(
    state == "NY", 
    year %in% c(2006,2010)
    ) %>% 
  ggplot(aes(x = response, y = data_value)) + 
  geom_boxplot() + 
  facet_grid(.~year)

NY_response_df
```

In this problem, we focused on the topic of 'Overall Health'. Firstly, changed the variable names, for example, 'locationabbr' was changed into 'state. Then, values of variable 'response' was reordered in levels of {Poor, Fair, Good, Very good, Excellent}. 

Looking at the data frame, in 2002, there were 36 states were observed at 7 or more locations. However, in 2010, there were 45 states were observed. 

Next, we constructed a dataset that limits to 'Excellent' responses, and grouped by 'year', 'state', and created a variable 'mean_value' that indicates the average values of 'data_value' across locations within a state. Graphed a spaghetti plot that shows lines for the mean value of each state across years. 

Lastly, generated a two-panel plot showing the distribution of 'data_value' for response in 2006 and 2010 for NY state. 